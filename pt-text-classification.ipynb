{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7613204,"sourceType":"datasetVersion","datasetId":4433445}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from huggingface_hub import login\nlogin()","metadata":{"_uuid":"e494527c-4f52-4c6c-94a6-4d43b75a28f8","_cell_guid":"bfec5243-185a-4a7b-95a0-31e478cd9f3f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-13T19:16:52.926946Z","iopub.execute_input":"2024-02-13T19:16:52.927329Z","iopub.status.idle":"2024-02-13T19:16:52.952086Z","shell.execute_reply.started":"2024-02-13T19:16:52.927296Z","shell.execute_reply":"2024-02-13T19:16:52.951374Z"},"trusted":true},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64eba89f63c04fbd9efc619cf738ae81"}},"metadata":{}}]},{"cell_type":"code","source":"!pip install  sentencepiece datasets peft  evaluate  -U accelerate -U transformers","metadata":{"execution":{"iopub.status.busy":"2024-02-13T17:17:00.269599Z","iopub.execute_input":"2024-02-13T17:17:00.270005Z","iopub.status.idle":"2024-02-13T17:17:35.413771Z","shell.execute_reply.started":"2024-02-13T17:17:00.269972Z","shell.execute_reply":"2024-02-13T17:17:35.412630Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.1.99)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nCollecting datasets\n  Downloading datasets-2.17.0-py3-none-any.whl.metadata (20 kB)\nCollecting peft\n  Downloading peft-0.8.2-py3-none-any.whl.metadata (25 kB)\nCollecting evaluate\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.26.1)\nCollecting accelerate\n  Downloading accelerate-0.27.2-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.37.0)\nCollecting transformers\n  Downloading transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.24.4)\nCollecting pyarrow>=12.0.0 (from datasets)\n  Downloading pyarrow-15.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\nCollecting pyarrow-hotfix (from datasets)\n  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nCollecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets)\n  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.20.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.1.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.2)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.11.17)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading datasets-2.17.0-py3-none-any.whl (536 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.6/536.6 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading peft-0.8.2-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.4/183.4 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow-15.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\nInstalling collected packages: pyarrow-hotfix, pyarrow, fsspec, accelerate, transformers, datasets, peft, evaluate\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 11.0.0\n    Uninstalling pyarrow-11.0.0:\n      Successfully uninstalled pyarrow-11.0.0\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2023.12.2\n    Uninstalling fsspec-2023.12.2:\n      Successfully uninstalled fsspec-2023.12.2\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.26.1\n    Uninstalling accelerate-0.26.1:\n      Successfully uninstalled accelerate-0.26.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.37.0\n    Uninstalling transformers-4.37.0:\n      Successfully uninstalled transformers-4.37.0\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.1.0\n    Uninstalling datasets-2.1.0:\n      Successfully uninstalled datasets-2.1.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.0 which is incompatible.\nbeatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.0.11 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.3.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 15.0.0 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\ndask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ngcsfs 2023.12.2.post1 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\nraft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ns3fs 2023.12.2 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-0.27.2 datasets-2.17.0 evaluate-0.4.1 fsspec-2023.10.0 peft-0.8.2 pyarrow-15.0.0 pyarrow-hotfix-0.6 transformers-4.37.2\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import  load_dataset, Dataset, DatasetDict, concatenate_datasets\n\nfrom transformers import (\n    AutoTokenizer,\n    AutoConfig,\n    AutoModelForSequenceClassification,\n    DataCollatorWithPadding,\n    TrainingArguments,\n    Trainer\n)\n\nfrom peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\nimport evaluate\nimport torch\nimport numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-02-13T17:17:35.415296Z","iopub.execute_input":"2024-02-13T17:17:35.415628Z","iopub.status.idle":"2024-02-13T17:17:53.325587Z","shell.execute_reply.started":"2024-02-13T17:17:35.415591Z","shell.execute_reply":"2024-02-13T17:17:53.324729Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2024-02-13 17:17:41.875490: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-13 17:17:41.875608: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-13 17:17:42.008970: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"data = pd.read_json(\"/kaggle/input/reviews/reviews.json\")\ndata.text = data.text.astype(str)\ndata = data.sample(frac=1).reset_index(drop=True) ## 73665 rows\n\n\nfifty = int(len(data) * 0.7)\ndata = data[:fifty] \n\n\nid2c = {0: 'neg', 1:'neutral', 2: 'pos'}\nc2id = {\"neg\": 0, \"neutral\": 1, \"pos\": 2}\ndata['sentiment'].unique()\n\ndef get_features(row):\n    y = 0 if row['sentiment'] == 'neg' else 1 if row['sentiment'] == 'neutral' else 2\n    return {'text': row['text'], 'label': y}\n\n\nsize = int(len(data) * 0.2)\ntreino = data[size:]\nteste = data[:size]\n\n\ntrain_dict_list = treino.apply(get_features, axis=1).tolist()\n\ntrainDataset = Dataset.from_dict({\"text\": [item['text'] for item in train_dict_list], \"label\": [item['label'] for item in train_dict_list]})\n\nvalidation_dict_list = teste.apply(get_features, axis=1).tolist()\n\nvalidationDataset = Dataset.from_dict({\"text\": [item['text'] for item in validation_dict_list], \"label\": [item['label'] for item in validation_dict_list]})\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T17:17:53.328501Z","iopub.execute_input":"2024-02-13T17:17:53.329241Z","iopub.status.idle":"2024-02-13T17:17:56.388469Z","shell.execute_reply.started":"2024-02-13T17:17:53.329206Z","shell.execute_reply":"2024-02-13T17:17:56.387665Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"dataset = DatasetDict({\"train\": trainDataset, \"validation\": validationDataset})\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-02-13T17:17:56.389835Z","iopub.execute_input":"2024-02-13T17:17:56.390097Z","iopub.status.idle":"2024-02-13T17:17:56.400181Z","shell.execute_reply.started":"2024-02-13T17:17:56.390073Z","shell.execute_reply":"2024-02-13T17:17:56.399288Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 41252\n    })\n    validation: Dataset({\n        features: ['text', 'label'],\n        num_rows: 10313\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"model_repo = \"distilbert/distilbert-base-multilingual-cased\"","metadata":{"execution":{"iopub.status.busy":"2024-02-13T17:17:56.401310Z","iopub.execute_input":"2024-02-13T17:17:56.401650Z","iopub.status.idle":"2024-02-13T17:17:57.130856Z","shell.execute_reply.started":"2024-02-13T17:17:56.401625Z","shell.execute_reply":"2024-02-13T17:17:57.129881Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(model_repo, num_labels=3, id2label=id2c, label2id=c2id)\ntokenizer = AutoTokenizer.from_pretrained(model_repo, add_prefix_space=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T17:17:57.132179Z","iopub.execute_input":"2024-02-13T17:17:57.132504Z","iopub.status.idle":"2024-02-13T17:18:10.164352Z","shell.execute_reply.started":"2024-02-13T17:17:57.132478Z","shell.execute_reply":"2024-02-13T17:18:10.163569Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/466 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56d7cac226a7443f8d4be7b550fafc25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/542M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3246388d7eb14df1810f4babd56857b0"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76cc2d2d16034ffdb179d5f20c8ca88c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c36545ef93984bdb9e5c80cd6cdd5280"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5eda400936c447ebc4429bda2f809fc"}},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_items(examples):\n  text = examples[\"text\"]\n\n  tokenizer.truncation_side = \"left\"\n  tokenized_inputs = tokenizer(\n      text,\n      return_tensors=\"pt\",\n      truncation=True,\n      padding=True,\n      max_length=512\n  )\n\n  # Convertendo tensores para matrizes numpy\n  numpy_tokenized_inputs = {key: value.numpy() for key, value in tokenized_inputs.items()}\n\n  return numpy_tokenized_inputs\n\nif tokenizer.pad_token is None:\n  tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n  model.resize_token_embeddings(len(tokenizer))\ntokenized_dataset = dataset.map(tokenize_items, batched=True)\ntokenized_dataset","metadata":{"execution":{"iopub.status.busy":"2024-02-13T17:18:10.165611Z","iopub.execute_input":"2024-02-13T17:18:10.165923Z","iopub.status.idle":"2024-02-13T17:18:43.596398Z","shell.execute_reply.started":"2024-02-13T17:18:10.165895Z","shell.execute_reply":"2024-02-13T17:18:43.595545Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/41252 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"042c8d43ea27472eb5ba000c820dc4e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10313 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2902094e65d426d800fc765b8744d9e"}},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label', 'input_ids', 'attention_mask'],\n        num_rows: 41252\n    })\n    validation: Dataset({\n        features: ['text', 'label', 'input_ids', 'attention_mask'],\n        num_rows: 10313\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T17:18:43.597945Z","iopub.execute_input":"2024-02-13T17:18:43.598492Z","iopub.status.idle":"2024-02-13T17:18:43.603230Z","shell.execute_reply.started":"2024-02-13T17:18:43.598457Z","shell.execute_reply":"2024-02-13T17:18:43.602333Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score\naccuracy = evaluate.load('accuracy')\n\ndef compute_metrics(p):\n  predictions, labels = p\n  predictions = np.argmax(predictions, axis=1)\n  f1 = f1_score(predictions, labels, average='macro')\n\n  return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels), \"f1_score\": f1}","metadata":{"execution":{"iopub.status.busy":"2024-02-13T17:18:43.607245Z","iopub.execute_input":"2024-02-13T17:18:43.607685Z","iopub.status.idle":"2024-02-13T17:18:45.218330Z","shell.execute_reply.started":"2024-02-13T17:18:43.607660Z","shell.execute_reply":"2024-02-13T17:18:45.217425Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"782b28872fc5480d905dc43e034a37e2"}},"metadata":{}}]},{"cell_type":"code","source":"## Untrained model predictions\ntext_list = [\"Grande erro da rede globo hoje!!\", \"Gostei muito do jogo do corinthians hoje\", \"Que prova dificil\"]\n\n\nfor text in text_list:\n  inputs = tokenizer.encode(text, return_tensors=\"pt\")\n  logits = model(inputs).logits\n\n\n  predictions = torch.argmax(logits)\n  print(text + \" - \" + id2c[predictions.tolist()])","metadata":{"execution":{"iopub.status.busy":"2024-02-13T17:18:45.219580Z","iopub.execute_input":"2024-02-13T17:18:45.219922Z","iopub.status.idle":"2024-02-13T17:18:45.421934Z","shell.execute_reply.started":"2024-02-13T17:18:45.219888Z","shell.execute_reply":"2024-02-13T17:18:45.420975Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Grande erro da rede globo hoje!! - neg\nGostei muito do jogo do corinthians hoje - neg\nQue prova dificil - neg\n","output_type":"stream"}]},{"cell_type":"code","source":"peft_config = LoraConfig(\n                task_type=\"SEQ_CLS\", ##sequence classification,\n                r=4, ##intrinsic rank of trainable weight matrix\n                lora_alpha=32, ##this is like learning rate\n                lora_dropout=0.01, ## probality of dropout\n                target_modules = ['q_lin'] ##we apply lora to query layer\n              )","metadata":{"execution":{"iopub.status.busy":"2024-02-13T17:18:45.423167Z","iopub.execute_input":"2024-02-13T17:18:45.423472Z","iopub.status.idle":"2024-02-13T17:18:45.428082Z","shell.execute_reply.started":"2024-02-13T17:18:45.423446Z","shell.execute_reply":"2024-02-13T17:18:45.427117Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-02-13T17:18:45.429195Z","iopub.execute_input":"2024-02-13T17:18:45.429482Z","iopub.status.idle":"2024-02-13T17:18:45.453711Z","shell.execute_reply.started":"2024-02-13T17:18:45.429457Z","shell.execute_reply":"2024-02-13T17:18:45.452893Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"trainable params: 629,763 || all params: 135,956,742 || trainable%: 0.46320836373086965\n","output_type":"stream"}]},{"cell_type":"code","source":"#hyperparameters\nlr =  1e-3\nbatch_size = 4\nnum_epochs = 5\n\ntraining_args = TrainingArguments(\n    output_dir = model_repo + \"-lora-multilingual-text-classification\",\n    learning_rate = lr,\n    per_device_train_batch_size = batch_size,\n    per_device_eval_batch_size = batch_size,\n    num_train_epochs = num_epochs,\n    weight_decay = 0.01,\n    evaluation_strategy = \"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T17:18:45.456689Z","iopub.execute_input":"2024-02-13T17:18:45.457021Z","iopub.status.idle":"2024-02-13T17:18:45.489791Z","shell.execute_reply.started":"2024-02-13T17:18:45.456997Z","shell.execute_reply":"2024-02-13T17:18:45.488899Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer( \n    model = model, \n    args=training_args, \n    train_dataset=tokenized_dataset[\"train\"], \n    eval_dataset=tokenized_dataset[\"validation\"], \n    tokenizer=tokenizer, \n    data_collator=data_collator, ##this will dynamically pad examples in each batch \n    compute_metrics=compute_metrics \n)\n\n    \ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-02-13T17:38:05.528319Z","iopub.execute_input":"2024-02-13T17:38:05.529003Z","iopub.status.idle":"2024-02-13T19:04:27.330129Z","shell.execute_reply.started":"2024-02-13T17:38:05.528972Z","shell.execute_reply":"2024-02-13T19:04:27.329342Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='51565' max='51565' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [51565/51565 1:26:21, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1 Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.378500</td>\n      <td>0.440187</td>\n      <td>{'accuracy': 0.8783089304760981}</td>\n      <td>0.896805</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.362200</td>\n      <td>0.383574</td>\n      <td>{'accuracy': 0.8894599049743043}</td>\n      <td>0.905927</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.341900</td>\n      <td>0.371197</td>\n      <td>{'accuracy': 0.8969262096383206}</td>\n      <td>0.912401</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.364000</td>\n      <td>0.382034</td>\n      <td>{'accuracy': 0.8984776495685057}</td>\n      <td>0.913733</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.390200</td>\n      <td>0.392245</td>\n      <td>{'accuracy': 0.8998351595074178}</td>\n      <td>0.914643</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Trainer is attempting to log a value of \"{'accuracy': 0.8783089304760981}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nCheckpoint destination directory distilbert/distilbert-base-multilingual-cased-lora-multilingual-text-classification/checkpoint-10313 already exists and is non-empty.Saving will proceed but saved results may be invalid.\nTrainer is attempting to log a value of \"{'accuracy': 0.8894599049743043}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'accuracy': 0.8969262096383206}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'accuracy': 0.8984776495685057}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'accuracy': 0.8998351595074178}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=51565, training_loss=0.3521191885038339, metrics={'train_runtime': 5181.3372, 'train_samples_per_second': 39.808, 'train_steps_per_second': 9.952, 'total_flos': 2.77222500919296e+16, 'train_loss': 0.3521191885038339, 'epoch': 5.0})"},"metadata":{}}]},{"cell_type":"code","source":"## Trained model predictionsd\ntext_list = [\"Grande erro da rede globo hoje\", \"Gostei muito do jogo do corinthians hoje\", \"Que prova dificil\"]\n\nmodel.to(\"cpu\")\n\nfor text in text_list:\n  inputs1 = tokenizer.encode(text, return_tensors=\"pt\")\n  logits1 = model(inputs1).logits\n\n\n  predictions1 = torch.argmax(logits1)\n  str = text + \" - \" + id2c[predictions1.tolist()]\n  str","metadata":{"execution":{"iopub.status.busy":"2024-02-13T19:15:21.652525Z","iopub.execute_input":"2024-02-13T19:15:21.652887Z","iopub.status.idle":"2024-02-13T19:15:21.764850Z","shell.execute_reply.started":"2024-02-13T19:15:21.652856Z","shell.execute_reply":"2024-02-13T19:15:21.763961Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"inputs = tokenizer.encode(\"Nao gostei desse produto, pessima qualidade\", return_tensors=\"pt\")\nlogits = model(inputs).logits\n\n\npredictions = torch.argmax(logits)\nid2c[predictions.tolist()]","metadata":{"execution":{"iopub.status.busy":"2024-02-13T19:15:58.786065Z","iopub.execute_input":"2024-02-13T19:15:58.786483Z","iopub.status.idle":"2024-02-13T19:15:58.837507Z","shell.execute_reply.started":"2024-02-13T19:15:58.786449Z","shell.execute_reply":"2024-02-13T19:15:58.836440Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"'neg'"},"metadata":{}}]},{"cell_type":"code","source":"model.save_pretrained(\"pt-trained-model\")\n\npeft_model = \"igoramf/lora-pt-sentiment-analysis\"\n\nmodel.push_to_hub(\n    peft_model, use_auth_token=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T19:17:00.879620Z","iopub.execute_input":"2024-02-13T19:17:00.880325Z","iopub.status.idle":"2024-02-13T19:17:05.406494Z","shell.execute_reply.started":"2024-02-13T19:17:00.880288Z","shell.execute_reply":"2024-02-13T19:17:05.405773Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:821: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/129 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ce1ef1e8aad4964a7e797793c108a7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/2.52M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0712fe9f780847fdb37e9cbc210c61b9"}},"metadata":{}},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/igoramf/lora-pt-sentiment-analysis/commit/a89ffdcf024d9b43e9ed39e9b8831f46d1b372ec', commit_message='Upload model', commit_description='', oid='a89ffdcf024d9b43e9ed39e9b8831f46d1b372ec', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]}]}